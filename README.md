# Neural-Network-Library



# activation functions:

- ReLu
- Sigmoid
- Linear
- Softmax

# loss functions:

- Binary Crossentropy
- Categorical Crossentropy
- Mse(Mean squared error)

# Layers:

- Input layer
- Dense layer

# Weight Initializations:

- Random Initialization
- He Initialization 
